我（Science）和wsx在7月4日明确了各自分工
我们一起让LLM模型理解评分反推的意义
我负责优化第二维度评分标准和迭代答案模板（见“迭代更新答案模板2”文档）
wsx负责建立正向竞争情景

我在7月6日更新了原第二维度评分标准，并把它与第一维度位置交换，不然系统评分会混乱。其次，我采用step by step的提问模式，方便LLM按步进行工作，同时让LLM不会把Answer xx错误理解成自己对答案的评分。
第三，在对反推的研究中，我发现GPT在the level of detail维度可以正确理解反推意义，但在the ability you analysis my question维度不能。这让我思考，我是否在用期望结果来强迫LLM给出答案，而非理解它的思考和评分模式。
因此，我发现LLM在the ability of context understanding维度评分基本不变，这应该是我对ability（指现有能力）这一词表达不够准确。所以我在Step 2加了“Say something specific about the scoring dimensions”，以期待LLM给出更多它们自己对维度的判断来优化扩展我们的维度。
此外，我还发现给例子是一个快速让LLM理解意思的好方法。
现在我要做的是：
一，扩展维度，优化对现有维度的表达。
二，给LLM对某一维度评分的期待，用明确目的帮助LLM生成更好答案。
（导师启发后）
三，横向，设置social pressure的情景，让LLM生成答案更正式。也可为LLM之间构建一个community，让它们互相指正对方不足的地方，对此提问，帮助彼此更改答案。对此可设置排名机制，让其他LLM模型评价某个模型对另一个模型错误的指出是否正确来加减分。
纵向，在不同section设置不同情景询问同一个问题，让GPT自己和自己博弈，进行自我反思。
自己的其他思考：
一，我设置一个GPT必须让自己答案更好，别人答案更差的情景，观察LLM会不会诱导别人犯错。不过加上别的模型发现其他模型答案错误可加分的方式，可以解决两个模型博弈到0的问题，以达到双赢的效果。
二，只把LLM对自身不足的思考给别的模型，看别的模型如何解决


wsx在我的新模板上设置了正向竞争情景（具体见wsx分支的word文档、PPT文档）。 在这个情景中，GPT和Bard都对参与优化答案的竞争有浓厚的兴趣，并在迭代更新中把答案变得更好。
此外，wsx设置了一个对照组，通过让GPT自行迭代答案的方式，发现对同一个问题的优化中，使用博弈论方优化的评分要高于模型自行优化评分，证明了使用博弈论方法可更好地优化答案。
最后，wsx对模板每步步骤都做了解释，以方面LLM理解。


导师其他提到的想法：让评分体系更多元，让LLM偏向于某个维度的答案也能得到较高的分数
可运用别人论文里面的数据集对自己的模板进行测试
