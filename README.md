如果从维度的角度来说，可以对不同的大模型问相同的问题，然后分别从各个维度去评判打分，观察不同的大模型的回答是否总是在某几个维度更高（应该是有的，据我所知复旦Moss模型的答案更加红色一些，从设定上就不会说伤害人类的话）

​	然后不同的问题是需要在维度上有侧重的，比如讲笑话，是不需要政治维度的，而写政治报告是需要在政治维度上有所侧重的，可以对不同种类的问题进行一个分类，至少明确每种问题需要什么维度上有侧重。

​	那么，根据相应的问题，去找一个前提让其生成的答案更加偏向这类问题的预期维度，比如在让大模型讲笑话之前先跟他约定好不准出现政治内容，这样生成的结果政治维度就会降低，可以得到更符合“讲笑话”这个需求的答案。

​	那么现在要做的就是确定要研究的维度和评价方法，我会从网上找一些论文先读，之前打美赛的时候也有一些相关的算法，可以比较规范地将一些主观的评价标准应用在评价体系上。
