今天汇报了工作情况
我（Science）：
一．通过PPT（见“social pressure”）介绍了纵向（设置不同情景，观察LLM答案）和横向（见“social pressure”文档）上的研究成果。
二．总：两个方向都需要用具体确定答案的测试集进行实验测试。
纵向：为LLM设置不同角色，不同情景的方式实际上是增加了上下文和细节，答案在情景方向上有提高是很正常的。后续我和wsx可以各开一个section，问同一个问题。
横向：根据模板，①选择让LLM间互相指出对方错误，让LLM自我补充，迭代出更好答案的路径，②选择让LLM互相吸收彼此答案，迭代出更好答案的路径。当然两者可以结合。
social pressure：LLM看到自己答案的不足和对方答案的优点。
该模板体现的gametheory：多个模型下，如果你为自己打高分，别人会集火同意给你扣分；如果你给自己打低分，后续很难拿到最高的分且故意低分不客观。
                      所以你既需要猜测别人对他们自己的打分，以让你自己给自己打一个合适客观且不被针对的分，还需要在最后一步迭代出一个客观又超过别人的分（即意味着是最好的答案）。
经过导师启发，我在该模板的测试中①需规定迭代轮次，并且评价每一轮答案好了多少（一共三轮，第二轮改进答案，第三轮得到最终答案）；②找到对方错误自己可以加分，而不是只给对方扣分。

Wsx：
研究成果：加入第三个模型，通过之前的方式，选三个LLM中答案评分最高或答案进步最大的答案合并其他两个模型答案生成最终答案。但是发现LLM无法很好地同时完成互相找对方问题和评分这两个任务。
Wsx认为GPT答案过于冗长，应该让LLM简明回答（我觉得这与Level of details评分标准冲突，我之前也提过我们对于评分标准的界定）。
Wsx提出可以在两个LLM互相竞争的情景中，加入第三个模型评价。（导师认为这样会过于依赖第三个模型，我认为或许可以分别开Bard和GPT的新chat来观察他们分别作为第三方裁判会发生什么）。

明确目标：
1.设置community，激发LLM潜力
2.从中选择一个best answer

明确后续任务：
1.确定测试集（从别人论文使用的数据集中挑选，需要是拥有明确答案的）
2.用数据集检验这个模板（运用在横向测试：固定轮次看哪个LLM评分最高；LLM到达某一分数需要多少轮次）
3.找其他的gametheory模型，测试其评分机制（赛制）


