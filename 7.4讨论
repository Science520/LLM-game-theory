今天我（Science）和另外一名成员（wsx）汇报了近期研究成果
我研究方向：多个大模型迭代更新出更好答案的模板
具体模板见main文件（“迭代更新答案”），我使用GPT和Bard两个模型进行测试
今天通过讲解一个案例完成对整个模板的介绍（PPT“迭代更新讲解”见附件）。之前案例测试集中在how-to和what-is的问题，LLM会给出分点建议和具体答案。评分提高主要体现在第三维度更多细节的加入，此时GPT和Bard评分都很正常。但在做PPT时，我尝试了open-writing的答案，此时Bard在第二维度给分出现了问题。根据PPT可知Bard在第二维度评分具体问题在评分结果未运用到具体运算中，并且第二维度评分变为越依赖文本，给分越高，但总体评分降低，这在how-to和what-is问题中是未出现的。证明Bard还未完全理解维度间加权计算与总分的关系。
其次，GPT在回溯理解上能力不够：当更多细节加入，第三维度评分升高，但倒推回Answer 1应因第三维度扩展，在第三维度打分降低，从而总体评分降低，可在这却出现GPT在第三维度评分升高的问题，证明GPT还未完全理解维度评分的意义。
还有，Bard在一开始回答完问题后，给了对补充detail的建议，我们是否可以将LLM模型自身认为自己不足的地方告诉对方，彼此帮对方解决。
现在我要做的是：
一，解决第二维度评分变化问题。我将采用以5分（一半引用，一半LLM自己创造）为真正最高分的方法（见PPT），这样可减少每次问题迭代更新需要确定各个维度评分不出错的工作，减少初始化时间。
二，帮助GPT理解维度评分意义，增强其推理能力。
三，探索其他相关维度，并写出更好的模板，减少过多需要添加的补丁。


wsx研究方向：借鉴荣格八维评分体系制定四个对立维度，并出题测试LLM性格
具体模板见wsx分支
可以通过这些题目测试LLM答题倾向，通过改变对立维度占比，以获得更符合某些方面需求的答案。wsx研究更偏向于纵向测试单个模型，改变性格占比，以获得更好答案。wsx之后会更新一些测试样例。目前可能存在LLM每一次结合上下文答题都会改变自身性格占比，以及人为改变占比，不清楚LLM是否真正理解命令含义的问题。
（我认为该方向可能会在后续推进结合博弈论，赋予角色性格的研究中用到。）


后续工作会先围绕我横向的思路展开研究，探索能运用到多个模型中迭代更新出最好答案的模板。

